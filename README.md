# RAG чат-бот по документации [OnCloud](https://oncloud.ru/documentation)


## Описание проекта

Проект решает задачу автоматизации ответов на вопросы по технической документации на примере сервиса OnCloud. Система извлекает релевантные фрагменты текста (чанки) из базы знаний и генерирует ответы, используя комбинацию ретривера (поиск) и генеративной модели. Основные этапы:

1. **Парсинг документации**: парсинг документации с сайта OnCloud и сохранение в структурированный CSV-файл (data/documentation.csv).
2. **Чанкинг**: разделение текста на фрагменты для эффективного поиска.
3. **Создание эмбеддингов**: преобразование текста в векторы с помощью модели для русского языка.
4. **RAG**: поиск релевантных чанков и генерация ответов на основе контекста (запроса пользователя).

Проект оптимизирован для работы на GPU (например, Google Colab с T4).

---

## Стек

- **Язык программирования**: Python
- **Парсинг**: `requests`, `BeautifulSoup`
- **Чанкинг**: `langchain`
- **Эмбеддинги**: `sentence-transformers` (`DeepPavlov/rubert-base-cased-sentence`)
- **Векторный поиск**: `faiss-cpu`
- **Генерация текста**: `transformers` (`IlyaGusev/saiga_llama3_8b`)
- **Фреймворк ML**: `torch`
- **Обработка CSV**: `pandas`

---

## Этапы разработки

### 1. Парсинг документации
- **Цель**: собрать данные с сайта OnCloud.
- **Процесс**:
  - Использованы библиотеки `requests` для HTTP-запросов и `BeautifulSoup` для парсинга HTML.
  - Собраны данные из 17 подразделов документации.
  - Данные сохранены в `data/documentation.csv` с колонками:
    - `subsection`: название подраздела
    - `source`: URL страницы
    - `content`: текст документации

### 2. Чанкинг текста
- **Цель**: разделить текст на фрагменты для эффективного поиска.
- **Процесс**:
  - Использован `langchain.RecursiveCharacterTextSplitter` с размером чанка 512 токенов и перекрытием 50 токенов.
  - Токенизация выполнена с помощью `DeepPavlov/rubert-base-cased-sentence` для точного подсчёта токенов на русском языке.
  - Результат: 79 чанков, сохранены в `data/chunks.json` с полями:
    - `chunk_id`: уникальный идентификатор
    - `subsection`: подраздел
    - `source`: URL
    - `content`: текст чанка

### 3. Создание эмбеддингов
- **Цель**: преобразовать чанки в векторы для векторного поиска.
- **Процесс**:
  - Использована модель `DeepPavlov/rubert-base-cased-sentence`, оптимизированная для русского языка.
  - Сгенерированы 768-мерные эмбеддинги для каждого чанка.
  - Эмбеддинги сохранены в `data/embeddings_rubert.npy`.
  - Создан FAISS-индекс (`data/faiss_index_rubert.bin`) для быстрого поиска.

### 4. RAG-система
- **Цель**: реализовать поиск релевантных чанков и генерацию ответов.
- **Процесс**:
  - **Ретривер**: использована `DeepPavlov/rubert-base-cased-sentence` для кодирования запросов и FAISS для поиска релевантных чанков.
  - **Генерация**: модель `IlyaGusev/saiga_llama3_8b` генерирует ответы.

---

## Пример работы (из блокнота с инференсом)

<img width="1787" height="743" alt="Screenshot from 2025-09-10 23-12-34" src="https://github.com/user-attachments/assets/d95068fe-e5b9-4d34-95cf-b706783f346f" />

*Скриншот: консольный вывод с запросом, чанками и ответом.*

---

## Использование

Проверить работу RAG-системы (начиная с создания чанков и заканчивая инференсом модели) можно в [блокноте Colab]([url](https://colab.research.google.com/drive/1kh8Zu4Os5ZXpUCZ15_oDR0mOiv0yoiqt?usp=sharing)).

Перенесети данные из папки data этого репозитория в среду Colab для работы. 

**Примечание**: убедитесь, что в Colab включён GPU (Runtime → Change runtime type → T4 GPU) для ускорения работы модели.
